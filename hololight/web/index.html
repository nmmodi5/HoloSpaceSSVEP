<!doctype html>
<!--
Copyright 2018 The Immersive Web Community Group

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-->

<!--
  "Lightbulb" (https://skfb.ly/6RzwQ) by Autaritus is licensed under Creative
  Commons Attribution (http://creativecommons.org/licenses/by/4.0/).
-->
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">

    <title>Hololight Demo</title>
  </head>
  <body>
    <header>
      <details open>
        <summary>Hololight Demo</summary>
        <p>
          Augmented Reality BCI Demonstration.
        </p>
      </details>
    </header>
    <script type="module">
      import {WebXRButton} from './js/util/webxr-button.js';
      import {Scene} from './js/render/scenes/scene.js';
      import {Renderer, createWebGLContext} from './js/render/core/renderer.js';
      import {Node} from './js/render/core/node.js';
      import {Gltf2Node} from './js/render/nodes/gltf2.js';
      import {ButtonNodeIcon} from './js/render/nodes/button-static.js';
      import {DropShadowNode} from './js/render/nodes/drop-shadow.js';
      import {vec3} from './js/render/math/gl-matrix.js';
      import {Ray} from './js/render/math/ray.js';

      // XR globals.
      let xrButton = null;
      let xrRefSpace = null;
      let xrViewerSpace = null;
      let xrHitTestSource = null;
      let xrGLFactory = null;

      let ws_global;

      // WebGL scene globals.
      let gl = null;
      let renderer = null;
      let scene = new Scene();
      scene.enableStats(false);

      let arObject = new Node();
      arObject.visible = false;
      scene.addNode(arObject);

      let quad = new ButtonNodeIcon();
      vec3.set(quad.scale, 2, 2, 2);
      arObject.addNode(quad);

      let flower = new Gltf2Node({url: 'assets/sunflower.gltf'});
      flower.visible = false;
      scene.addNode(flower);

      let reticle = new Gltf2Node({url: 'assets/reticle.gltf'});
      reticle.visible = false;
      scene.addNode(reticle);

      const MAX_QUADS = 4;
      let quads = [];
      let frequency = [8, 10, 12, 15]; // should be of length MAX_QUADS
      let startTime = [0, 0, 0, 0]; // should be of length MAX_QUADS
      let index = [0, 0, 0, 0]; // should be of length MAX_QUADS
      let visibility = [true, false];
      let runTime = 10000; // total time of flashing, in milliseconds
      // let selectionTime = 10000; // wait for first 10 seconds for user to select SSVEP location
      //let firstQuadSelectStartTime = 0 // set only first time 1st quad starts blinking.
      let integrationStartTime = 0; // set to timestamp when integration time starts i.e. last quadrant is selected
      let startSSVEPDecodeMessageFlag = false;
      let flowerDisplayTime = 2000 // display the flower at decoded location for this much time (in ms)

      let light_mapping = false;
      let map_light = null;
      let sel_quad = null;

      // Ensure the background is transparent for AR.
      scene.clear = false;

      function initXR() {
        xrButton = new WebXRButton({
          onRequestSession: onRequestSession,
          onEndSession: onEndSession,
          textEnterXRTitle: "START AR",
          textXRNotFoundTitle: "AR NOT FOUND",
          textExitXRTitle: "EXIT  AR",
        });
        document.querySelector('header').appendChild(xrButton.domElement);

        if (navigator.xr) {
          navigator.xr.isSessionSupported('immersive-ar')
                      .then((supported) => {
            xrButton.enabled = supported;
          });
        }
      }

      function onRequestSession() {
        return navigator.xr.requestSession('immersive-ar', {requiredFeatures: ['local', 'hit-test']})
                           .then((session) => {
          xrButton.setSession(session);
          onSessionStarted(session);
        });
      }

      function onSessionStarted(session) {
        session.addEventListener('end', onSessionEnded);
        session.addEventListener('select', onSelect);

        if (!gl) {
          gl = createWebGLContext({
            xrCompatible: true
          });

          renderer = new Renderer(gl);

          scene.setRenderer(renderer);
        }

        xrGLFactory = new XRWebGLBinding(session, gl);

        session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });

        // In this sample we want to cast a ray straight out from the viewer's
        // position and render a reticle where it intersects with a real world
        // surface. To do this we first get the viewer space, then create a
        // hitTestSource that tracks it.
        session.requestReferenceSpace('viewer').then((refSpace) => {
          xrViewerSpace = refSpace;
          session.requestHitTestSource({ space: xrViewerSpace }).then((hitTestSource) => {
            xrHitTestSource = hitTestSource;
          });
        });

        session.requestReferenceSpace('local').then((refSpace) => {
          xrRefSpace = refSpace;

          session.requestAnimationFrame(onXRFrame);
        });
      }

      function onEndSession(session) {
        xrHitTestSource.cancel();
        xrHitTestSource = null;
        session.end();
      }

      function onSessionEnded(event) {
        xrButton.setSession(null);
      }

      // Adds a new object to the scene at the
      // specified transform.
      function addARObjectAt(matrix) {
        let newquad = arObject.clone();
        newquad.visible = true;
        newquad.matrix = matrix;
        scene.addNode(newquad);
        quads.push(newquad);

        /* // For performance reasons if we add too many objects start
        // removing the oldest ones to keep the scene complexity
        // from growing too much.
        if (quads.length > MAX_QUADS) {
          let oldquad = quads.shift();
          scene.removeNode(oldquad);
          let old_freq = frequency.shift();
          frequency[MAX_QUADS-1] = old_freq;
          let oldStartTime = startTime.shift();
          startTime[MAX_QUADS-1] = 0;
        } */
        return newquad
      }

      // Function to display the flower at the specified position.
      function displayFlowerAt(matrix) {
        flower.visible = true;
        flower.matrix = matrix;
      }

      // Event listener added to session
      // This in turn adds the ARObject quad
      function onSelect(event) {
        if (reticle.visible && quads.length <= MAX_QUADS) {
          // The reticle should already be positioned at the latest hit point, 
          // so we can just use it's matrix to save an unnecessary call to 
          // event.frame.getHitTestResults.
          // Quads are added only before integration start time
          // as reticles are not rendered afer that
          quad = addARObjectAt(reticle.matrix);
        }
      }

      // Called every time a XRSession requests that a new frame be drawn.
      function onXRFrame(t, frame) {
        let session = frame.session;
        let pose = frame.getViewerPose(xrRefSpace);

        reticle.visible = false;

        // If we have a hit test source, get its results for the frame
        // and use the pose to display a reticle in the scene.
        // Reticle is visible only before the integration time starts (i.e. during selection time)
        if (xrHitTestSource && pose && integrationStartTime == 0) {
          let hitTestResults = frame.getHitTestResults(xrHitTestSource);
          if (hitTestResults.length > 0) {
            let pose = hitTestResults[0].getPose(xrRefSpace);
            reticle.visible = true;
            reticle.matrix = pose.transform.matrix;
          }
        }

        scene.startFrame();

        session.requestAnimationFrame(onXRFrame);

        scene.drawXRFrame(frame, pose);

        // Selection of spatial location by user before SSVEP starts
        if(!integrationStartTime) {
          if (quads.length == MAX_QUADS) {
            integrationStartTime = t;
          }
          /* quads.forEach(function(quad, i) {
            if (!startTime[i]) { startTime[i] = t; }
            if (!firstQuadSelectStartTime) { firstQuadSelectStartTime = startTime[0]}
            if(startTime[0] && ((t-firstQuadSelectStartTime) > selectionTime)) { 
              integrationStartTime = t;
            }
          }) */
        }
        // after selection time is expired (which is equivalent to selecting 4 quads on the AR scene)
        else {
          // Strobe quads for runtime at the set frequency
          if((t - integrationStartTime) < runTime) {
            quads.forEach(function(quad, i) {
              if (!startTime[i]) { startTime[i] = t; }
              const elapsed = t - startTime[i];
              const interval = Math.floor(1000/frequency[i]);   
              if (elapsed > interval) {
                startTime[i] = t;
                index[i] = ++(index[i])%2;
                quad.visible = visibility[index[i]];
              }
            })
          }
          // Once the strobing of quads is done, we send message to SSVEP decoder 
          // TODO: Work on adding an expiry timer incase startSSVEP decode starts but end flag never gets set
          else {
            // send message to ezmsg to start SSVEP decoding
            if(!startSSVEPDecodeMessageFlag) {
              // set all quads to invisble after runtime
              quads.forEach(function(quad, i) {
                quad.visible = false;
              })
              ws_global.send(`COMMAND: START_SSVEP_DECODE`);
              startSSVEPDecodeMessageFlag = true;
            }
          }
        }

        /* // Determine closest quad to reticle
        // Navin - This block will be useful later when 
        // we want to preprocess the location to send
        let closestquadDistance = null;
        let closestquad = null;
        quads.forEach(function(quad, i) {

          let distance = Math.hypot(
            reticle.matrix[12] - quad.matrix[12],
            reticle.matrix[13] - quad.matrix[13],
            reticle.matrix[14] - quad.matrix[14],
          )

          if (distance <= 0.33)
            if (closestquad == null || closestquadDistance > distance) { 
              closestquad = quad;
              closestquadDistance = distance;
            }
        })

        if (closestquad != sel_quad) {
          sel_quad = closestquad;
          if(!light_mapping)
            ws_global.send(`SELECT: ${sel_quad == null ? "null" : closestquad.light}`);
        } */

        scene.endFrame();
      }

      function connectToWebsocket() {
        return new Promise(function(resolve, reject) {
          const hostname = location.hostname
          const ws = new WebSocket('wss://' + hostname + ':8082');
          ws.onopen = () => resolve(ws);
          ws.onerror = (err) => reject(err);
        });
      }

      async function on_message( event ) {
        let tokens = event.data.split( ": " )
        console.log( 'message from ezmsg', tokens )

        if(tokens[0] == 'CLASS'){
          // Put a flower on location decoded that corresponds to that frequency for that scene, 
          // given by quads[tokens[1]].matrix 
          //console.log( 'token is', tokens[1], 'class decoded in Hz is', frequency[tokens[1]] );
          // ws_global.send(`STATUS: RECEIVED token is ${tokens[1]}, class decoded is ${frequency[tokens[1]]} Hz`);
          // ws_global.send(`STATUS: Displaying flower at ${quads[tokens[1]].matrix}`);
          displayFlowerAt(quads[tokens[1]].matrix);
          // sleep function
          await new Promise(ms => setTimeout(ms, flowerDisplayTime));
          flower.visible = false;
          startSSVEPDecodeMessageFlag = false;
          integrationStartTime = 0;
          quads = [];
        }
      }

      // Start the XR application.
      connectToWebsocket().then(function(ws) {
        ws_global = ws;
        ws_global.addEventListener( 'message', on_message )
        initXR();
      }).catch(function(err) {
        console.log( err )
        console.log("Websocket connection failed")
      })

    </script>
  </body>
</html>
